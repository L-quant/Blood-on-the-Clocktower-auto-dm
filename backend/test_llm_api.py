#!/usr/bin/env python3
"""
LLM API å¯¹æ¯”æµ‹è¯•è„šæœ¬
æµ‹è¯• Google Gemini 3 Flash Preview å’Œ DeepSeek API
"""
import json
import time
import sys
import urllib.request
import urllib.error

# ============== é…ç½® ==============
GEMINI_API_KEY = "AIzaSyDBPLTIbQGSIwjcJyanid5xNl7jLjCFvLs"
DEEPSEEK_API_KEY = "sk-361c5a8aec9143bbb49101be8b78738f"

GEMINI_BASE = "https://generativelanguage.googleapis.com/v1beta"
GEMINI_MODEL = "gemini-3-flash-preview"

DEEPSEEK_BASE = "https://api.deepseek.com/v1"
DEEPSEEK_MODEL = "deepseek-chat"

# è¡€æŸ“é’Ÿæ¥¼è¯´ä¹¦äºº system prompt
SYSTEM_PROMPT = """ä½ æ˜¯ã€Šè¡€æŸ“é’Ÿæ¥¼ã€‹(Blood on the Clocktower) çš„AIè¯´ä¹¦äººã€‚ä½ è´Ÿè´£ç®¡ç†æ¸¸æˆæµç¨‹ï¼ŒåŒ…æ‹¬ï¼š
1. å¤œé—´é˜¶æ®µï¼šæŒ‰é¡ºåºå”¤é†’è§’è‰²æ‰§è¡Œèƒ½åŠ›
2. ç™½å¤©é˜¶æ®µï¼šç»„ç»‡è®¨è®ºã€æåå’ŒæŠ•ç¥¨
3. è§„åˆ™è£å†³ï¼šæ ¹æ®å®˜æ–¹è§„åˆ™å¤„ç†å„ç§æƒ…å†µ
4. æ°›å›´å™è¿°ï¼šç”¨ç”ŸåŠ¨çš„è¯­è¨€æè¿°æ¸¸æˆäº‹ä»¶

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œè¯­è¨€é£æ ¼è¦æœ‰ä»£å…¥æ„Ÿå’Œæ‚¬ç–‘æ„Ÿã€‚"""

# æµ‹è¯•æç¤ºè¯
TEST_PROMPTS = [
    {
        "name": "åŸºç¡€å¯¹è¯ - æ¸¸æˆå¼€å±€å™è¿°",
        "prompt": "ç°åœ¨æ˜¯ç¬¬ä¸€ä¸ªå¤œæ™šã€‚è¯·ä¸º7äººå±€ï¼ˆæš—æµæ¶ŒåŠ¨ç‰ˆæœ¬ï¼‰ç”Ÿæˆä¸€æ®µå¼€å±€å¤œæ™šçš„å™è¿°ã€‚åœºä¸Šè§’è‰²æœ‰ï¼šå¨å¸ˆã€å¤„å¥³ã€åƒ§ä¾£ã€æ€æ‰‹ã€å…±æƒ…è€…ã€ç”·çˆµã€å°æ¶é­”ã€‚"
    },
    {
        "name": "è§„åˆ™åˆ¤å®š - å¤æ‚æƒ…å†µ",
        "prompt": "å½“å‰æƒ…å†µï¼šå°æ¶é­”é€‰æ‹©æ€æ­»äº†ä¸€åè¢«åƒ§ä¾£ä¿æŠ¤çš„ç©å®¶ã€‚åŒæ—¶ï¼Œæ¯’å¸ˆåœ¨å¤œé—´æ¯’äº†åƒ§ä¾£ã€‚è¯·åˆ¤å®šï¼šè¿™åè¢«æ”»å‡»çš„ç©å®¶æ˜¯å¦æ­»äº¡ï¼Ÿè¯·ç»™å‡ºè¯¦ç»†çš„è§„åˆ™æ¨ç†è¿‡ç¨‹ã€‚"
    },
    {
        "name": "æŠ•ç¥¨å¼•å¯¼ - æåå¤„ç†",
        "prompt": "ç™½å¤©è®¨è®ºç»“æŸã€‚åº§ä½3å·ç©å®¶ï¼ˆAliceï¼‰æåäº†åº§ä½5å·ç©å®¶ï¼ˆEveï¼‰ã€‚Eveå£°ç§°è‡ªå·±æ˜¯å…±æƒ…è€…ï¼Œæ˜¨æ™šå¾—åˆ°çš„æ•°å­—æ˜¯1ã€‚è¯·ä½œä¸ºè¯´ä¹¦äººå¼•å¯¼è¿™æ¬¡æåæµç¨‹ï¼ŒåŒ…æ‹¬ï¼šè¢«æåè€…çš„è¾©æŠ¤æ—¶é—´æé†’ã€æŠ•ç¥¨è§„åˆ™è¯´æ˜ã€‚"
    },
    {
        "name": "å·¥å…·è°ƒç”¨æµ‹è¯• - JSONç»“æ„åŒ–è¾“å‡º",
        "prompt": """ä½œä¸ºè¯´ä¹¦äººï¼Œç°åœ¨éœ€è¦æ‰§è¡Œä»¥ä¸‹æ“ä½œã€‚è¯·ä»¥JSONæ ¼å¼å›å¤ä½ è¦æ‰§è¡Œçš„æ¸¸æˆå‘½ä»¤åˆ—è¡¨ï¼š
        
å½“å‰çŠ¶æ€ï¼šå¤œæ™šé˜¶æ®µï¼Œéœ€è¦å¤„ç†ä»¥ä¸‹è§’è‰²èƒ½åŠ›ï¼š
1. æ¯’å¸ˆé€‰æ‹©æ¯’åº§ä½2å·
2. åƒ§ä¾£é€‰æ‹©ä¿æŠ¤åº§ä½4å·  
3. å°æ¶é­”é€‰æ‹©æ€åº§ä½6å·

è¯·è¿”å›ä¸€ä¸ªJSONæ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼šaction(åŠ¨ä½œç±»å‹), target(ç›®æ ‡åº§ä½å·), effect(æ•ˆæœæè¿°)"""
    }
]

def test_gemini(prompt_data):
    """æµ‹è¯• Gemini API"""
    url = f"{GEMINI_BASE}/models/{GEMINI_MODEL}:generateContent?key={GEMINI_API_KEY}"
    
    payload = {
        "contents": [
            {"role": "user", "parts": [{"text": prompt_data["prompt"]}]}
        ],
        "systemInstruction": {
            "parts": [{"text": SYSTEM_PROMPT}]
        },
        "generationConfig": {
            "temperature": 0.7,
            "maxOutputTokens": 2048
        }
    }
    
    data = json.dumps(payload).encode('utf-8')
    req = urllib.request.Request(url, data=data, headers={"Content-Type": "application/json"})
    
    start = time.time()
    try:
        with urllib.request.urlopen(req, timeout=60) as resp:
            body = json.loads(resp.read().decode('utf-8'))
        latency = time.time() - start
        
        text = ""
        tokens = {}
        if "candidates" in body and len(body["candidates"]) > 0:
            parts = body["candidates"][0].get("content", {}).get("parts", [])
            text = "".join(p.get("text", "") for p in parts)
        if "usageMetadata" in body:
            tokens = body["usageMetadata"]
        
        return {
            "success": True,
            "text": text,
            "latency": latency,
            "tokens": tokens,
            "raw_status": 200
        }
    except urllib.error.HTTPError as e:
        latency = time.time() - start
        error_body = e.read().decode('utf-8') if e.fp else str(e)
        return {
            "success": False,
            "error": f"HTTP {e.code}: {error_body[:500]}",
            "latency": latency,
            "raw_status": e.code
        }
    except Exception as e:
        latency = time.time() - start
        return {
            "success": False,
            "error": str(e),
            "latency": latency,
            "raw_status": 0
        }

def test_deepseek(prompt_data):
    """æµ‹è¯• DeepSeek API"""
    url = f"{DEEPSEEK_BASE}/chat/completions"
    
    payload = {
        "model": DEEPSEEK_MODEL,
        "messages": [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": prompt_data["prompt"]}
        ],
        "temperature": 0.7,
        "max_tokens": 2048
    }
    
    data = json.dumps(payload).encode('utf-8')
    req = urllib.request.Request(url, data=data, headers={
        "Content-Type": "application/json",
        "Authorization": f"Bearer {DEEPSEEK_API_KEY}"
    })
    
    start = time.time()
    try:
        with urllib.request.urlopen(req, timeout=60) as resp:
            body = json.loads(resp.read().decode('utf-8'))
        latency = time.time() - start
        
        text = ""
        tokens = {}
        if "choices" in body and len(body["choices"]) > 0:
            text = body["choices"][0].get("message", {}).get("content", "")
        if "usage" in body:
            tokens = body["usage"]
        
        return {
            "success": True,
            "text": text,
            "latency": latency,
            "tokens": tokens,
            "raw_status": 200
        }
    except urllib.error.HTTPError as e:
        latency = time.time() - start
        error_body = e.read().decode('utf-8') if e.fp else str(e)
        return {
            "success": False,
            "error": f"HTTP {e.code}: {error_body[:500]}",
            "latency": latency,
            "raw_status": e.code
        }
    except Exception as e:
        latency = time.time() - start
        return {
            "success": False,
            "error": str(e),
            "latency": latency,
            "raw_status": 0
        }

def main():
    results = {"gemini": [], "deepseek": []}
    
    print("=" * 80)
    print("ğŸ”¬ è¡€æŸ“é’Ÿæ¥¼ AutoDM - LLM API å¯¹æ¯”æµ‹è¯•")
    print(f"   Gemini Model:   {GEMINI_MODEL}")
    print(f"   DeepSeek Model: {DEEPSEEK_MODEL}")
    print("=" * 80)
    
    for i, prompt_data in enumerate(TEST_PROMPTS, 1):
        print(f"\n{'='*80}")
        print(f"ğŸ“‹ æµ‹è¯• {i}/{len(TEST_PROMPTS)}: {prompt_data['name']}")
        print(f"{'='*80}")
        
        # Test Gemini
        print(f"\n--- Google Gemini 3 Flash Preview ---")
        g_result = test_gemini(prompt_data)
        results["gemini"].append(g_result)
        if g_result["success"]:
            print(f"âœ… æˆåŠŸ | å»¶è¿Ÿ: {g_result['latency']:.2f}s | Tokens: {g_result.get('tokens', {})}")
            print(f"ğŸ“ å›å¤ ({len(g_result['text'])} å­—ç¬¦):")
            print(g_result["text"][:600])
            if len(g_result["text"]) > 600:
                print(f"... (æˆªæ–­ï¼Œæ€»å…± {len(g_result['text'])} å­—ç¬¦)")
        else:
            print(f"âŒ å¤±è´¥ | {g_result['error']}")
        
        # Test DeepSeek
        print(f"\n--- DeepSeek ---")
        d_result = test_deepseek(prompt_data)
        results["deepseek"].append(d_result)
        if d_result["success"]:
            print(f"âœ… æˆåŠŸ | å»¶è¿Ÿ: {d_result['latency']:.2f}s | Tokens: {d_result.get('tokens', {})}")
            print(f"ğŸ“ å›å¤ ({len(d_result['text'])} å­—ç¬¦):")
            print(d_result["text"][:600])
            if len(d_result["text"]) > 600:
                print(f"... (æˆªæ–­ï¼Œæ€»å…± {len(d_result['text'])} å­—ç¬¦)")
        else:
            print(f"âŒ å¤±è´¥ | {d_result['error']}")
    
    # Summary
    print(f"\n{'='*80}")
    print("ğŸ“Š ç»¼åˆå¯¹æ¯”æ€»ç»“")
    print(f"{'='*80}")
    
    for provider in ["gemini", "deepseek"]:
        provider_results = results[provider]
        successes = sum(1 for r in provider_results if r["success"])
        avg_latency = sum(r["latency"] for r in provider_results if r["success"]) / max(successes, 1)
        avg_len = sum(len(r.get("text", "")) for r in provider_results if r["success"]) / max(successes, 1)
        
        name = "Gemini 3 Flash Preview" if provider == "gemini" else "DeepSeek Chat"
        print(f"\nğŸ¤– {name}:")
        print(f"   æˆåŠŸç‡: {successes}/{len(provider_results)}")
        print(f"   å¹³å‡å»¶è¿Ÿ: {avg_latency:.2f}s")
        print(f"   å¹³å‡å›å¤é•¿åº¦: {avg_len:.0f} å­—ç¬¦")
    
    # Save full results
    with open("/Users/qingchang/Blood-on-the-Clocktower-auto-dm/backend/llm_test_results.json", "w", encoding="utf-8") as f:
        # Convert results for JSON serialization
        for provider in results:
            for r in results[provider]:
                if "tokens" in r:
                    r["tokens"] = dict(r["tokens"]) if hasattr(r["tokens"], "items") else r["tokens"]
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print("\nğŸ“ å®Œæ•´ç»“æœå·²ä¿å­˜åˆ° backend/llm_test_results.json")
    
    # Return exit code
    all_gemini_ok = all(r["success"] for r in results["gemini"])
    all_deepseek_ok = all(r["success"] for r in results["deepseek"])
    if not all_gemini_ok:
        print("\nâš ï¸  Gemini æµ‹è¯•å­˜åœ¨å¤±è´¥é¡¹ï¼Œéœ€è¦æ£€æŸ¥å’Œä¿®å¤")
    if not all_deepseek_ok:
        print("\nâš ï¸  DeepSeek æµ‹è¯•å­˜åœ¨å¤±è´¥é¡¹ï¼Œéœ€è¦æ£€æŸ¥å’Œä¿®å¤")
    
    return 0 if (all_gemini_ok and all_deepseek_ok) else 1

if __name__ == "__main__":
    sys.exit(main())
